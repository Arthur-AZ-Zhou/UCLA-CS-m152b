{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D08rnyXBTybx",
        "outputId": "22fde76c-f2f4-4fee-d9e8-6fd16fc700ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries loaded and hardware constants defined.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import struct\n",
        "\n",
        "# Hardware Constraints per Specification\n",
        "INPUT_SIZE = 784\n",
        "HIDDEN_SIZE = 128\n",
        "OUTPUT_SIZE = 10\n",
        "NUM_BANKS = 64\n",
        "MAX_DSP_OUTPUT = 2**47  # 48-bit accumulator\n",
        "QTZ_INT8_MIN = -128\n",
        "QTZ_INT8_MAX = 127\n",
        "QTZ_UINT8_MIN = 0\n",
        "QTZ_UINT8_MAX = 255\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries loaded and hardware constants defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data - We keep it simple (0-1 float) for training,\n",
        "# but will map to 0-255 integers for the FPGA.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Converts 0-255 image to 0.0-1.0 float\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "print(\"MNIST Data downloaded and loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtBDXr6qT6mj",
        "outputId": "f342ab44-0e1a-4497-d9cf-deca4f8e6411"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.09MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.26MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST Data downloaded and loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "class FPGA_MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FPGA_MLP, self).__init__()\n",
        "        # Layer 1: 784 -> 128. Bias=False to match DSP accumulator logic\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE, HIDDEN_SIZE, bias=False)\n",
        "        self.relu = nn.ReLU()\n",
        "        # Layer 2: 128 -> 10. Bias=False\n",
        "        self.fc2 = nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = FPGA_MLP()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvHULeFCUDoC",
        "outputId": "b34481a5-220d-431e-ec62-2c42bfd7888d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FPGA_MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=False)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Adam optimizer with weight decay for regularization\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# OneCycleLR scheduler: peaks at max_lr then decays\n",
        "# total_steps = epochs * batches_per_epoch\n",
        "EPOCHS = 5\n",
        "steps_per_epoch = len(train_loader)\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.001,  # Peak learning rate\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    pct_start=0.3,  # Spend 30% of training in warmup phase\n",
        "    anneal_strategy='cos'  # Cosine annealing\n",
        ")\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update LR after each batch\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\t'\n",
        "                  f'Loss: {loss.item():.6f}\\tLR: {scheduler.get_last_lr()[0]:.6f}')\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Accuracy: {correct}/{len(test_loader.dataset)} ({acc:.2f}%)\\n')\n",
        "    return acc\n",
        "\n",
        "# Train for 5 epochs with OneCycleLR\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch)\n",
        "    test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCvWkyCWUJbb",
        "outputId": "6c90a15c-ba4e-4d38-ce9e-09bb160e1663"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.291802\tLR: 0.000040\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.125274\tLR: 0.000052\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.700594\tLR: 0.000088\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.140324\tLR: 0.000145\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.663009\tLR: 0.000220\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.548114\tLR: 0.000311\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.489534\tLR: 0.000412\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.354959\tLR: 0.000518\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.241430\tLR: 0.000624\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.289036\tLR: 0.000725\n",
            "\n",
            "Test set: Accuracy: 9214/10000 (92.14%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.236718\tLR: 0.000762\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.202321\tLR: 0.000847\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.191626\tLR: 0.000917\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.098998\tLR: 0.000967\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.235850\tLR: 0.000995\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.197196\tLR: 0.001000\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.206819\tLR: 0.000996\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.074907\tLR: 0.000988\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.163099\tLR: 0.000975\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.160427\tLR: 0.000958\n",
            "\n",
            "Test set: Accuracy: 9511/10000 (95.11%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.178977\tLR: 0.000950\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.123975\tLR: 0.000927\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.089746\tLR: 0.000900\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.153903\tLR: 0.000870\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.271810\tLR: 0.000836\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.195108\tLR: 0.000799\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.172910\tLR: 0.000760\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.188763\tLR: 0.000718\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.064760\tLR: 0.000674\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.097358\tLR: 0.000628\n",
            "\n",
            "Test set: Accuracy: 9647/10000 (96.47%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.055557\tLR: 0.000610\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.082109\tLR: 0.000563\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.099251\tLR: 0.000516\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.066578\tLR: 0.000468\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.107439\tLR: 0.000420\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.030230\tLR: 0.000373\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.050563\tLR: 0.000328\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.099461\tLR: 0.000284\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.044049\tLR: 0.000242\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.186662\tLR: 0.000202\n",
            "\n",
            "Test set: Accuracy: 9688/10000 (96.88%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.120152\tLR: 0.000188\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.110482\tLR: 0.000152\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.031011\tLR: 0.000119\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.065153\tLR: 0.000090\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.059786\tLR: 0.000064\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.072748\tLR: 0.000043\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.098196\tLR: 0.000026\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.065187\tLR: 0.000013\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.138538\tLR: 0.000004\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.041552\tLR: 0.000000\n",
            "\n",
            "Test set: Accuracy: 9703/10000 (97.03%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observers to store min/max values\n",
        "stats = {\n",
        "    'input_min': 0, 'input_max': 0,\n",
        "    'l1_out_min': 0, 'l1_out_max': 0,\n",
        "    # Note: Layer 2 output is logits, we don't strictly need to quantize\n",
        "    # the final output for Argmax, but we will for completeness.\n",
        "}\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Pass a batch of data to calibrate\n",
        "    data_iter = iter(train_loader)\n",
        "    images, _ = next(data_iter)\n",
        "    images = images.to(device)\n",
        "\n",
        "    # Input Stats (Should be 0.0 to 1.0)\n",
        "    flat_img = images.view(-1, 784)\n",
        "    stats['input_max'] = flat_img.max().item()\n",
        "\n",
        "    # Layer 1 Output Stats (Before ReLU)\n",
        "    l1_out = model.fc1(flat_img)\n",
        "    stats['l1_out_max'] = l1_out.max().item()\n",
        "    stats['l1_out_min'] = l1_out.min().item()\n",
        "\n",
        "    print(\"Calibration Stats:\", stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h0rTiY7Uk7z",
        "outputId": "7e1dbf81-e129-40b2-a590-2a7fd38068b8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibration Stats: {'input_min': 0, 'input_max': 1.0, 'l1_out_min': -9.771818161010742, 'l1_out_max': 7.377934455871582}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Quantization Scales ---\n",
        "\n",
        "# Input scale: MNIST images are normalized [0, 1], map to [0, 255]\n",
        "S_input = 1.0 / 255.0\n",
        "\n",
        "# Layer 1 output scale (after fc1, before ReLU)\n",
        "# Use symmetric quantization for signed values\n",
        "S_l1_out = max(abs(stats['l1_out_min']), abs(stats['l1_out_max'])) / 127.0\n",
        "\n",
        "print(f\"S_input: {S_input:.6f}\")\n",
        "print(f\"S_l1_out: {S_l1_out:.6f}\")\n",
        "\n",
        "# --- Quantize Weights ---\n",
        "\n",
        "# Extract weights from trained model\n",
        "W1_fp32 = model.fc1.weight.data.cpu().numpy()  # Shape: [128, 784]\n",
        "W2_fp32 = model.fc2.weight.data.cpu().numpy()  # Shape: [10, 128]\n",
        "\n",
        "# Calculate weight scales (symmetric quantization to int8)\n",
        "S_w1 = np.max(np.abs(W1_fp32)) / 127.0\n",
        "S_w2 = np.max(np.abs(W2_fp32)) / 127.0\n",
        "\n",
        "print(f\"S_w1: {S_w1:.6f}\")\n",
        "print(f\"S_w2: {S_w2:.6f}\")\n",
        "\n",
        "# Quantize weights to int8\n",
        "W1_q = np.round(W1_fp32 / S_w1).astype(np.int8)\n",
        "W2_q = np.round(W2_fp32 / S_w2).astype(np.int8)\n",
        "\n",
        "print(f\"W1_q shape: {W1_q.shape}, dtype: {W1_q.dtype}\")\n",
        "print(f\"W2_q shape: {W2_q.shape}, dtype: {W2_q.dtype}\")\n",
        "\n",
        "# Verify quantization error\n",
        "w1_error = np.mean(np.abs(W1_fp32 - (W1_q * S_w1)))\n",
        "w2_error = np.mean(np.abs(W2_fp32 - (W2_q * S_w2)))\n",
        "print(f\"W1 quantization error (MAE): {w1_error:.6f}\")\n",
        "print(f\"W2 quantization error (MAE): {w2_error:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb_rJ4ySg2Ez",
        "outputId": "013f05ee-dc94-4fda-ef6b-4d6223a841e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S_input: 0.003922\n",
            "S_l1_out: 0.076943\n",
            "S_w1: 0.004329\n",
            "S_w2: 0.006170\n",
            "W1_q shape: (128, 784), dtype: int8\n",
            "W2_q shape: (10, 128), dtype: int8\n",
            "W1 quantization error (MAE): 0.000919\n",
            "W2 quantization error (MAE): 0.001512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def get_shift_only_param(real_multiplier):\n",
        "    \"\"\"\n",
        "    Approximates a float multiplier (e.g., 0.0034) using ONLY a bit shift.\n",
        "    Mathematically: Finds N such that 2^(-N) ~= real_multiplier\n",
        "    \"\"\"\n",
        "    if real_multiplier <= 0:\n",
        "        return 0 # Should not happen with ReLU\n",
        "\n",
        "    # We want: real_multiplier ~= 1.0 / (2^shift)\n",
        "    # So: shift ~= -log2(real_multiplier)\n",
        "    shift = round(-math.log2(real_multiplier))\n",
        "\n",
        "    # Clamp shift to reasonable values (e.g., 0 to 31)\n",
        "    shift = max(0, min(31, int(shift)))\n",
        "\n",
        "    # Calculate the actual scale we ended up with\n",
        "    actual_scale = 1.0 / (2**shift)\n",
        "    error = abs(actual_scale - real_multiplier) / real_multiplier\n",
        "\n",
        "    print(f\"Target: {real_multiplier:.5f} | Shift: {shift} | Actual: {actual_scale:.5f} | Error: {error*100:.1f}%\")\n",
        "    return shift\n",
        "\n",
        "# --- Recalculate Scales for Shift-Only ---\n",
        "\n",
        "# 1. Effective Scale for Layer 1\n",
        "M_effective_l1 = (S_input * S_w1) / S_l1_out\n",
        "print(\"Layer 1 Param:\")\n",
        "shift_l1 = get_shift_only_param(M_effective_l1)\n",
        "\n",
        "# 2. Effective Scale for Layer 2\n",
        "# (Reusing previous S_logits calculation)\n",
        "S_logits = 10.0 / 127.0\n",
        "M_effective_l2 = (S_l1_out * S_w2) / S_logits\n",
        "print(\"Layer 2 Param:\")\n",
        "shift_l2 = get_shift_only_param(M_effective_l2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SX4hgN0Uws7",
        "outputId": "a9d90082-4c1b-4b02-9247-5e2aac8ce27c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1 Param:\n",
            "Target: 0.00022 | Shift: 12 | Actual: 0.00024 | Error: 10.7%\n",
            "Layer 2 Param:\n",
            "Target: 0.00603 | Shift: 7 | Actual: 0.00781 | Error: 29.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fpga_layer_sim_shift_only(input_vec, weights, shift, activation='relu'):\n",
        "    # 1. Matrix Vector Multiply (Accumulation in Int32/48)\n",
        "    acc = np.matmul(weights.astype(np.int32), input_vec.astype(np.int32))\n",
        "\n",
        "    # 2. ReLU\n",
        "    if activation == 'relu':\n",
        "        acc = np.maximum(acc, 0)\n",
        "\n",
        "    # 3. PURE SHIFT Requantization\n",
        "    # We perform a standard arithmetic right shift\n",
        "    output_val = acc >> shift\n",
        "\n",
        "    # 4. Saturation / Clipping to 0-255 (UInt8)\n",
        "    output = np.clip(output_val, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return output\n",
        "\n",
        "def run_fpga_inference_shift_only(image_tensor):\n",
        "    img_uint8 = (image_tensor.view(-1).numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    # Layer 1\n",
        "    l1_out = fpga_layer_sim_shift_only(img_uint8, W1_q, shift_l1, activation='relu')\n",
        "\n",
        "    # Layer 2\n",
        "    l2_out = fpga_layer_sim_shift_only(l1_out, W2_q, shift_l2, activation='none')\n",
        "\n",
        "    return np.argmax(l2_out)\n",
        "\n",
        "# Run Verification\n",
        "correct = 0\n",
        "total = 0\n",
        "limit = 1000\n",
        "\n",
        "print(\"Running Shift-Only Simulation...\")\n",
        "for i in range(limit):\n",
        "    img, target = test_dataset[i]\n",
        "    pred = run_fpga_inference_shift_only(img)\n",
        "    if pred == target:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "print(f\"FPGA (Shift-Only) Accuracy: {100.0 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mDIwvzmUxQD",
        "outputId": "acf570f6-a586-4237-86a1-d55ef1ba194a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Shift-Only Simulation...\n",
            "FPGA (Shift-Only) Accuracy: 97.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- MODEL EXPORT SUMMARY ---\")\n",
        "\n",
        "# 1. Quantized Weights\n",
        "# Ensure they are explicitly int8\n",
        "W1_final = W1_q.astype(np.int8)\n",
        "W2_final = W2_q.astype(np.int8)\n",
        "\n",
        "print(f\"Layer 1 Weights: {W1_final.shape} | Min: {W1_final.min()} | Max: {W1_final.max()} | dtype: {W1_final.dtype}\")\n",
        "print(f\"Layer 2 Weights: {W2_final.shape}  | Min: {W2_final.min()} | Max: {W2_final.max()} | dtype: {W2_final.dtype}\")\n",
        "\n",
        "# 2. Quantization Parameters (Shift Only)\n",
        "# Ensure they are standard Python integers\n",
        "shift_l1_final = int(shift_l1)\n",
        "shift_l2_final = int(shift_l2)\n",
        "\n",
        "print(f\"\\nLayer 1 Shift: {shift_l1_final}\")\n",
        "print(f\"Layer 2 Shift: {shift_l2_final}\")\n",
        "\n",
        "# 3. Validation\n",
        "if W1_final.shape != (128, 784):\n",
        "    print(\"WARNING: W1 shape mismatch! Expected (128, 784)\")\n",
        "if W2_final.shape != (10, 128):\n",
        "    print(\"WARNING: W2 shape mismatch! Expected (10, 128)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rWm1c2RU2AL",
        "outputId": "1d019138-de5f-42a1-d45b-7ebe486c477f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MODEL EXPORT SUMMARY ---\n",
            "Layer 1 Weights: (128, 784) | Min: -127 | Max: 68 | dtype: int8\n",
            "Layer 2 Weights: (10, 128)  | Min: -127 | Max: 84 | dtype: int8\n",
            "\n",
            "Layer 1 Shift: 12\n",
            "Layer 2 Shift: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Save to a compressed .npz file\n",
        "# This file contains everything needed to run the model on the FPGA\n",
        "outfile = 'mnist_model.npz'\n",
        "\n",
        "np.savez(\n",
        "    outfile,\n",
        "    # Weights (The Matrices)\n",
        "    w1=W1_final,\n",
        "    w2=W2_final,\n",
        "\n",
        "    # Shifts (The Scalars)\n",
        "    # We wrap them in numpy arrays because save/load works best with arrays\n",
        "    shift_l1=np.array(shift_l1_final),\n",
        "    shift_l2=np.array(shift_l2_final)\n",
        ")\n",
        "\n",
        "print(f\"Successfully saved model to: {outfile}\")\n",
        "print(\"Keys in file: ['w1', 'w2', 'shift_l1', 'shift_l2']\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx4zBhLOVkwk",
        "outputId": "c02ca3f8-f316-4a3e-e577-e9372dadd5c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model to: mnist_model.npz\n",
            "Keys in file: ['w1', 'w2', 'shift_l1', 'shift_l2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YenQ74a8cPTn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}