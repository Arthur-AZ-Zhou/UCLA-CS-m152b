{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D08rnyXBTybx",
        "outputId": "c54894d6-2f22-4afb-b871-07a4db27f084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries loaded and hardware constants defined.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import struct\n",
        "\n",
        "# Hardware Constraints per Specification\n",
        "INPUT_SIZE = 784\n",
        "HIDDEN_SIZE = 128\n",
        "OUTPUT_SIZE = 10\n",
        "NUM_BANKS = 64\n",
        "MAX_DSP_OUTPUT = 2**47  # 48-bit accumulator\n",
        "QTZ_INT8_MIN = -128\n",
        "QTZ_INT8_MAX = 127\n",
        "QTZ_UINT8_MIN = 0\n",
        "QTZ_UINT8_MAX = 255\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries loaded and hardware constants defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtBDXr6qT6mj",
        "outputId": "8aa79905-7b82-4305-ae67-cce7f852422f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 22.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 600kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.57MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.08MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST Data downloaded and loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Prepare data - We keep it simple (0-1 float) for training,\n",
        "# but will map to 0-255 integers for the FPGA.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Converts 0-255 image to 0.0-1.0 float\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "print(\"MNIST Data downloaded and loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvHULeFCUDoC",
        "outputId": "b786963d-1f7b-41c9-fd40-bbc01140e4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPGA_MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=False)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class FPGA_MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FPGA_MLP, self).__init__()\n",
        "        # Layer 1: 784 -> 128. Bias=False to match DSP accumulator logic\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE, HIDDEN_SIZE, bias=False)\n",
        "        self.relu = nn.ReLU()\n",
        "        # Layer 2: 128 -> 10. Bias=False\n",
        "        self.fc2 = nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = FPGA_MLP()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCvWkyCWUJbb",
        "outputId": "a1dbeaad-fad9-444d-fbcb-942527fc6624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.284154\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.736994\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.242716\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.308300\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.440437\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.212209\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.310566\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.095364\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.249017\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.125816\n",
            "\n",
            "Test set: Accuracy: 9446/10000 (94.46%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.328347\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.177665\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.140001\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.169050\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.102580\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.067871\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.170210\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.084155\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.323227\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.186218\n",
            "\n",
            "Test set: Accuracy: 9632/10000 (96.32%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.062638\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.149118\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.088858\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.028786\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.308401\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.056021\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.128599\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.095243\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.159738\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.141058\n",
            "\n",
            "Test set: Accuracy: 9680/10000 (96.80%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Accuracy: {correct}/{len(test_loader.dataset)} ({acc:.2f}%)\\n')\n",
        "    return acc\n",
        "\n",
        "# Train for 3 epochs (usually enough for >92% on MNIST)\n",
        "for epoch in range(1, 4):\n",
        "    train(epoch)\n",
        "    test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h0rTiY7Uk7z",
        "outputId": "d3d6f546-c63f-4614-ef69-edbd4688b502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration Stats: {'input_min': 0, 'input_max': 1.0, 'l1_out_min': -12.523642539978027, 'l1_out_max': 8.765558242797852}\n"
          ]
        }
      ],
      "source": [
        "# Observers to store min/max values\n",
        "stats = {\n",
        "    'input_min': 0, 'input_max': 0,\n",
        "    'l1_out_min': 0, 'l1_out_max': 0,\n",
        "    # Note: Layer 2 output is logits, we don't strictly need to quantize\n",
        "    # the final output for Argmax, but we will for completeness.\n",
        "}\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Pass a batch of data to calibrate\n",
        "    data_iter = iter(train_loader)\n",
        "    images, _ = next(data_iter)\n",
        "    images = images.to(device)\n",
        "\n",
        "    # Input Stats (Should be 0.0 to 1.0)\n",
        "    flat_img = images.view(-1, 784)\n",
        "    stats['input_max'] = flat_img.max().item()\n",
        "\n",
        "    # Layer 1 Output Stats (Before ReLU)\n",
        "    l1_out = model.fc1(flat_img)\n",
        "    stats['l1_out_max'] = l1_out.max().item()\n",
        "    stats['l1_out_min'] = l1_out.min().item()\n",
        "\n",
        "    print(\"Calibration Stats:\", stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SX4hgN0Uws7",
        "outputId": "5cacf9a1-6d19-4e3a-a043-84fb55575405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 1 Param:\n",
            "Target: 0.00067 | Shift: 11 | Actual: 0.00049 | Error: 27.2%\n",
            "Layer 2 Param:\n",
            "Target: 0.00346 | Shift: 8 | Actual: 0.00391 | Error: 12.8%\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "def get_shift_only_param(real_multiplier):\n",
        "    \"\"\"\n",
        "    Approximates a float multiplier (e.g., 0.0034) using ONLY a bit shift.\n",
        "    Mathematically: Finds N such that 2^(-N) ~= real_multiplier\n",
        "    \"\"\"\n",
        "    if real_multiplier <= 0:\n",
        "        return 0 # Should not happen with ReLU\n",
        "\n",
        "    # We want: real_multiplier ~= 1.0 / (2^shift)\n",
        "    # So: shift ~= -log2(real_multiplier)\n",
        "    shift = round(-math.log2(real_multiplier))\n",
        "\n",
        "    # Clamp shift to reasonable values (e.g., 0 to 31)\n",
        "    shift = max(0, min(31, int(shift)))\n",
        "\n",
        "    # Calculate the actual scale we ended up with\n",
        "    actual_scale = 1.0 / (2**shift)\n",
        "    error = abs(actual_scale - real_multiplier) / real_multiplier\n",
        "\n",
        "    print(f\"Target: {real_multiplier:.5f} | Shift: {shift} | Actual: {actual_scale:.5f} | Error: {error*100:.1f}%\")\n",
        "    return shift\n",
        "\n",
        "# --- Recalculate Scales for Shift-Only ---\n",
        "\n",
        "# 1. Effective Scale for Layer 1\n",
        "M_effective_l1 = (S_input * S_w1) / S_l1_out\n",
        "print(\"Layer 1 Param:\")\n",
        "shift_l1 = get_shift_only_param(M_effective_l1)\n",
        "\n",
        "# 2. Effective Scale for Layer 2\n",
        "# (Reusing previous S_logits calculation)\n",
        "S_logits = 10.0 / 127.0\n",
        "M_effective_l2 = (S_l1_out * S_w2) / S_logits\n",
        "print(\"Layer 2 Param:\")\n",
        "shift_l2 = get_shift_only_param(M_effective_l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mDIwvzmUxQD",
        "outputId": "c91a7e31-20c1-4196-b3cd-d01a5495647d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Shift-Only Simulation...\n",
            "FPGA (Shift-Only) Accuracy: 96.90%\n"
          ]
        }
      ],
      "source": [
        "def fpga_layer_sim_shift_only(input_vec, weights, shift, activation='relu'):\n",
        "    # 1. Matrix Vector Multiply (Accumulation in Int32/48)\n",
        "    acc = np.matmul(weights.astype(np.int32), input_vec.astype(np.int32))\n",
        "\n",
        "    # 2. ReLU\n",
        "    if activation == 'relu':\n",
        "        acc = np.maximum(acc, 0)\n",
        "\n",
        "    # 3. PURE SHIFT Requantization\n",
        "    # We perform a standard arithmetic right shift\n",
        "    output_val = acc >> shift\n",
        "\n",
        "    # 4. Saturation / Clipping to 0-255 (UInt8)\n",
        "    output = np.clip(output_val, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return output\n",
        "\n",
        "def run_fpga_inference_shift_only(image_tensor):\n",
        "    img_uint8 = (image_tensor.view(-1).numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    # Layer 1\n",
        "    l1_out = fpga_layer_sim_shift_only(img_uint8, W1_q, shift_l1, activation='relu')\n",
        "\n",
        "    # Layer 2\n",
        "    l2_out = fpga_layer_sim_shift_only(l1_out, W2_q, shift_l2, activation='none')\n",
        "\n",
        "    return np.argmax(l2_out)\n",
        "\n",
        "# Run Verification\n",
        "correct = 0\n",
        "total = 0\n",
        "limit = 1000\n",
        "\n",
        "print(\"Running Shift-Only Simulation...\")\n",
        "for i in range(limit):\n",
        "    img, target = test_dataset[i]\n",
        "    pred = run_fpga_inference_shift_only(img)\n",
        "    if pred == target:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "print(f\"FPGA (Shift-Only) Accuracy: {100.0 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rWm1c2RU2AL",
        "outputId": "ba156b90-da6b-4fa0-d0ba-c6e29fbe740e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- MODEL EXPORT SUMMARY ---\n",
            "Layer 1 Weights: (128, 784) | Min: -127 | Max: 67 | dtype: int8\n",
            "Layer 2 Weights: (10, 128)  | Min: -127 | Max: 56 | dtype: int8\n",
            "\n",
            "Layer 1 Shift: 11\n",
            "Layer 2 Shift: 8\n"
          ]
        }
      ],
      "source": [
        "print(\"--- MODEL EXPORT SUMMARY ---\")\n",
        "\n",
        "# 1. Quantized Weights\n",
        "# Ensure they are explicitly int8\n",
        "W1_final = W1_q.astype(np.int8)\n",
        "W2_final = W2_q.astype(np.int8)\n",
        "\n",
        "print(f\"Layer 1 Weights: {W1_final.shape} | Min: {W1_final.min()} | Max: {W1_final.max()} | dtype: {W1_final.dtype}\")\n",
        "print(f\"Layer 2 Weights: {W2_final.shape}  | Min: {W2_final.min()} | Max: {W2_final.max()} | dtype: {W2_final.dtype}\")\n",
        "\n",
        "# 2. Quantization Parameters (Shift Only)\n",
        "# Ensure they are standard Python integers\n",
        "shift_l1_final = int(shift_l1)\n",
        "shift_l2_final = int(shift_l2)\n",
        "\n",
        "print(f\"\\nLayer 1 Shift: {shift_l1_final}\")\n",
        "print(f\"Layer 2 Shift: {shift_l2_final}\")\n",
        "\n",
        "# 3. Validation\n",
        "if W1_final.shape != (128, 784):\n",
        "    print(\"WARNING: W1 shape mismatch! Expected (128, 784)\")\n",
        "if W2_final.shape != (10, 128):\n",
        "    print(\"WARNING: W2 shape mismatch! Expected (10, 128)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx4zBhLOVkwk",
        "outputId": "8a76a9dc-5e09-4df8-e410-2f2ba537bc33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved model to: mnist_model.npz\n",
            "Keys in file: ['w1', 'w2', 'shift_l1', 'shift_l2']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Save to a compressed .npz file\n",
        "# This file contains everything needed to run the model on the FPGA\n",
        "outfile = 'mnist_model.npz'\n",
        "\n",
        "np.savez(\n",
        "    outfile,\n",
        "    # Weights (The Matrices)\n",
        "    w1=W1_final,\n",
        "    w2=W2_final,\n",
        "\n",
        "    # Shifts (The Scalars)\n",
        "    # We wrap them in numpy arrays because save/load works best with arrays\n",
        "    shift_l1=np.array(shift_l1_final),\n",
        "    shift_l2=np.array(shift_l2_final)\n",
        ")\n",
        "\n",
        "print(f\"Successfully saved model to: {outfile}\")\n",
        "print(\"Keys in file: ['w1', 'w2', 'shift_l1', 'shift_l2']\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YenQ74a8cPTn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
